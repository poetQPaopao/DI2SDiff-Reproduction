"""
PAMAP2 Dataset Loader

This module provides functions to load and preprocess the PAMAP2 dataset
for human activity recognition tasks.
"""

import pandas as pd
import numpy as np
import os
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from typing import Tuple, Optional

def load_pamap2_data(
    data_dir: str = '/root/.jupyter/lab/workspaces/PAMAP2_Dataset/Protocol',
    window_size: int = 128,
    overlap: float = 0.5,
    normalize: bool = True,
    test_size: float = 0.2,
    random_state: int = 42
) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    åŠ è½½PAMAP2æ•°æ®é›†
    
    Args:
        data_dir: PAMAP2æ•°æ®æ–‡ä»¶ç›®å½•
        window_size: æ»‘åŠ¨çª—å£å¤§å°
        overlap: çª—å£é‡å æ¯”ä¾‹
        normalize: æ˜¯å¦æ ‡å‡†åŒ–
        test_size: æµ‹è¯•é›†æ¯”ä¾‹
        random_state: éšæœºç§å­
    
    Returns:
        X_train, X_test, y_train, y_test, train_subjects, test_subjects
    """
    
    # PAMAP2æ´»åŠ¨æ ‡ç­¾æ˜ å°„
    activity_map = {
        1: 0,  # lying
        2: 1,  # sitting
        3: 2,  # standing
        4: 3,  # walking
        5: 4,  # running
        6: 5,  # cycling
        7: 6,  # Nordic walking
        12: 7, # ascending stairs
        13: 7, # descending stairs (åˆå¹¶ä¸ºclimbing stairs)
        16: 3, # vacuum cleaning (å½’ç±»ä¸ºwalking)
        17: 4, # ironing (å½’ç±»ä¸ºrunning)
        # 0, 8, 9, 10, 11, 14, 15, 18, 19, 20, 24 ç­‰å…¶ä»–æ´»åŠ¨å°†è¢«è¿‡æ»¤æ‰
    }
    
    # ä¼ æ„Ÿå™¨åˆ—å®šä¹‰ (åŸºäºPAMAP2æ•°æ®æ ¼å¼ï¼Œæ€»å…±54åˆ—)
    # åˆ—0: timestamp, åˆ—1: activity_id, åˆ—2: heart_rate
    # åˆ—3-15: IMU hand, åˆ—16-28: IMU chest, åˆ—29-41: IMU ankle
    # æ¯ä¸ªIMUåŒ…å«: temp, 3xåŠ é€Ÿåº¦, 3xé™€èºä»ª, 3xç£åŠ›è®¡, 4xå››å…ƒæ•°
    
    selected_columns = [
        # Chest IMU - åŠ é€Ÿåº¦è®¡ (3è½´) - åˆ—17,18,19
        17, 18, 19,
        # Chest IMU - é™€èºä»ª (3è½´) - åˆ—20,21,22
        20, 21, 22,
        # Chest IMU - ç£åŠ›è®¡ (3è½´) - åˆ—23,24,25
        23, 24, 25,
        # Hand IMU - åŠ é€Ÿåº¦è®¡ (3è½´) - åˆ—4,5,6
        4, 5, 6,
        # Ankle IMU - åŠ é€Ÿåº¦è®¡ (3è½´) - åˆ—30,31,32
        30, 31, 32,
        # å¿ƒç‡ (åˆ—2)
        2,
    ]
    
    all_data = []
    all_labels = []
    all_subjects = []
    
    print("ğŸ“Š å¼€å§‹åŠ è½½PAMAP2æ•°æ®...")
    
    # éå†æ‰€æœ‰å—è¯•è€…æ–‡ä»¶
    for filename in sorted(os.listdir(data_dir)):
        if not filename.endswith('.dat'):
            continue
            
        subject_id = int(filename.replace('subject', '').replace('.dat', ''))
        filepath = os.path.join(data_dir, filename)
        
        print(f"   å¤„ç†å—è¯•è€… {subject_id}: {filename}")
        
        try:
            # è¯»å–æ•°æ®æ–‡ä»¶
            data = pd.read_csv(filepath, sep=' ', header=None)
            print(f"    åŸå§‹æ•°æ®å½¢çŠ¶: {data.shape}")
            
            # è¿‡æ»¤æœ‰æ•ˆæ´»åŠ¨æ ‡ç­¾
            valid_activities = data[1].isin(list(activity_map.keys()))
            data = data[valid_activities]
            
            if len(data) == 0:
                print(f"å—è¯•è€… {subject_id} æ— æœ‰æ•ˆæ´»åŠ¨æ•°æ®")
                continue
                
            # æå–ä¼ æ„Ÿå™¨æ•°æ®å’Œæ ‡ç­¾
            sensor_data = data[selected_columns].values
            labels = data[1].values
            
            # ç§»é™¤åŒ…å«NaNçš„è¡Œ
            valid_mask = ~np.isnan(sensor_data).any(axis=1)
            sensor_data = sensor_data[valid_mask]
            labels = labels[valid_mask]
            
            if len(sensor_data) == 0:
                print(f"     å—è¯•è€… {subject_id} å¤„ç†åæ— æœ‰æ•ˆæ•°æ®")
                continue
                
            print(f"    å¤„ç†åæ•°æ®å½¢çŠ¶: {sensor_data.shape}")
            
            # æ»‘åŠ¨çª—å£åˆ†å‰²
            step_size = int(window_size * (1 - overlap))
            windows = []
            window_labels = []
            
            for i in range(0, len(sensor_data) - window_size + 1, step_size):
                window = sensor_data[i:i + window_size]
                window_label = labels[i:i + window_size]
                
                # æ£€æŸ¥çª—å£å†…æ ‡ç­¾ä¸€è‡´æ€§ (è‡³å°‘80%ç›¸åŒ)
                unique_labels, counts = np.unique(window_label, return_counts=True)
                if counts.max() / len(window_label) >= 0.8:
                    dominant_label = unique_labels[np.argmax(counts)]
                    if dominant_label in activity_map:
                        windows.append(window)
                        window_labels.append(activity_map[dominant_label])
            
            if len(windows) > 0:
                subject_windows = np.array(windows)
                subject_labels = np.array(window_labels)
                subject_ids = np.full(len(windows), subject_id)
                
                all_data.append(subject_windows)
                all_labels.append(subject_labels)
                all_subjects.append(subject_ids)
                
                print(f"     ç”Ÿæˆ {len(windows)} ä¸ªçª—å£")
            else:
                print(f"      å—è¯•è€… {subject_id} æ— æœ‰æ•ˆçª—å£")
                
        except Exception as e:
            print(f"     å¤„ç†å—è¯•è€… {subject_id} æ—¶å‡ºé”™: {e}")
            continue
    
    if not all_data:
        raise ValueError("âŒ æœªèƒ½åŠ è½½ä»»ä½•æœ‰æ•ˆæ•°æ®")
    
    # åˆå¹¶æ‰€æœ‰æ•°æ®
    X = np.concatenate(all_data, axis=0)  # [N, T, C]
    y = np.concatenate(all_labels, axis=0)
    subjects = np.concatenate(all_subjects, axis=0)
    
    print(f"\nğŸ“ˆ æ•°æ®åŠ è½½å®Œæˆ:")
    print(f"  æ€»æ ·æœ¬æ•°: {X.shape[0]}")
    print(f"  æ•°æ®å½¢çŠ¶: {X.shape}")
    print(f"  æ ‡ç­¾å½¢çŠ¶: {y.shape}")
    print(f"  å—è¯•è€…èŒƒå›´: {subjects.min()}-{subjects.max()}")
    
    # è½¬æ¢ä¸ºPyTorchæ ¼å¼ [N, C, T]
    X = X.transpose(0, 2, 1)
    
    # æ ‡å‡†åŒ–
    if normalize:
        print("ğŸ”„ æ‰§è¡Œæ•°æ®æ ‡å‡†åŒ–...")
        scaler = StandardScaler()
        N, C, T = X.shape
        X_reshaped = X.reshape(-1, C)
        X_normalized = scaler.fit_transform(X_reshaped)
        X = X_normalized.reshape(N, C, T)
    
    # æŒ‰æ ·æœ¬éšæœºåˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†ï¼ˆä¸æŒ‰å—è¯•è€…åˆ’åˆ†ï¼‰
    indices = np.arange(X.shape[0])
    train_indices, test_indices = train_test_split(
        indices, test_size=test_size, random_state=random_state, stratify=y
    )

    X_train = X[train_indices]
    X_test = X[test_indices]
    y_train = y[train_indices]
    y_test = y[test_indices]
    train_subjects = subjects[train_indices]
    test_subjects = subjects[test_indices]

    print(f"\nğŸ¯ æ•°æ®åˆ†å‰²å®Œæˆ:")
    print(f"  è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬, å—è¯•è€… {sorted(np.unique(train_subjects))}")
    print(f"  æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬, å—è¯•è€… {sorted(np.unique(test_subjects))}")
    
    # æ´»åŠ¨åˆ†å¸ƒç»Ÿè®¡
    print(f"\nğŸ“Š æ´»åŠ¨åˆ†å¸ƒç»Ÿè®¡:")
    activity_names = ['lying', 'sitting', 'standing', 'walking', 'running', 'cycling', 'nordic_walking', 'stairs']
    for i, name in enumerate(activity_names):
        train_count = np.sum(y_train == i)
        test_count = np.sum(y_test == i)
        total_count = train_count + test_count
        if total_count > 0:
            print(f"  {name}: è®­ç»ƒ {train_count}, æµ‹è¯• {test_count}, æ€»è®¡ {total_count}")
    
    return X_train, X_test, y_train, y_test, train_subjects, test_subjects

def save_pamap2_npy(
    X_train: np.ndarray,
    X_test: np.ndarray,
    y_train: np.ndarray, 
    y_test: np.ndarray,
    train_subjects: np.ndarray,
    test_subjects: np.ndarray,
    save_dir: str = 'pamap2_npy'
) -> None:
    """ä¿å­˜PAMAP2æ•°æ®ä¸ºnpyæ ¼å¼"""
    os.makedirs(save_dir, exist_ok=True)
    
    np.save(os.path.join(save_dir, 'X_train.npy'), X_train)
    np.save(os.path.join(save_dir, 'X_test.npy'), X_test)
    np.save(os.path.join(save_dir, 'y_train.npy'), y_train)
    np.save(os.path.join(save_dir, 'y_test.npy'), y_test)
    np.save(os.path.join(save_dir, 'subjects_train.npy'), train_subjects)
    np.save(os.path.join(save_dir, 'subjects_test.npy'), test_subjects)
    
    # åˆ›å»ºéªŒè¯é›† (ä½¿ç”¨æµ‹è¯•é›†çš„å‰¯æœ¬)
    np.save(os.path.join(save_dir, 'X_val.npy'), X_test)
    np.save(os.path.join(save_dir, 'y_val.npy'), y_test)
    
    print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ° {save_dir}/ ç›®å½•")

# é…ç½®å¸¸é‡
PAMAP2_CONFIG = {
    'num_features': 16,
    'num_classes': 8,
    'window_size': 128,
    'overlap': 0.5,
    'activity_names': ['lying', 'sitting', 'standing', 'walking', 'running', 'cycling', 'nordic_walking', 'stairs'],
    'activity_map': {
        1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 12: 7, 13: 7, 16: 3, 17: 4
    },
    'selected_columns': [17, 18, 19, 20, 21, 22, 23, 24, 25, 4, 5, 6, 30, 31, 32, 2]
}
